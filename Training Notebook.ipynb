{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55e46e48-95c5-41a4-b870-e145fd20fc32",
   "metadata": {},
   "source": [
    "# Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "401347a4-150d-4dd4-abc7-2036137eeb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from MPCNet.dataset import dataset\n",
    "from MPCNet.controller import utils\n",
    "from MPCNet.simulation import simulation\n",
    "from sklearn import preprocessing\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = [10, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93fadb26-7af8-4e6e-a83a-d3a7405531c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw,y = dataset.Dataset.load('data/data5-1000000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ef64f2a-9729-4608-b9c8-f64b4342eabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = preprocessing.StandardScaler().fit(X_raw)\n",
    "#X = scaler.transform(X_raw)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_raw, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49be4cd3-2b9c-4778-ae5c-17efdabc62b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizationLayer = tf.keras.layers.Normalization(axis=-1, input_dim=5)\n",
    "normalizationLayer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "210ec59e-0cdb-4fdb-8402-208c9068389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, lr, num_epochs = 5000, 0.001, 300\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "trainer = tf.keras.optimizers.Adam(learning_rate=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b88c3d67-d918-43b0-8621-97b2d7ae67e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_2 (Normalizat  (None, 5)                11        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 64)                384       \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,405\n",
      "Trainable params: 40,394\n",
      "Non-trainable params: 11\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net = tf.keras.models.Sequential([\n",
    "    normalizationLayer,\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8f3da4f0-47b8-4e74-90f8-8fb4fed838dc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.2349 - val_loss: 0.1365\n",
      "Epoch 2/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.1257 - val_loss: 0.1190\n",
      "Epoch 3/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.1145 - val_loss: 0.1103\n",
      "Epoch 4/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.1094 - val_loss: 0.1063\n",
      "Epoch 5/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.1059 - val_loss: 0.1059\n",
      "Epoch 6/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.1038 - val_loss: 0.1012\n",
      "Epoch 7/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.1014 - val_loss: 0.0989\n",
      "Epoch 8/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0995 - val_loss: 0.1012\n",
      "Epoch 9/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0981 - val_loss: 0.0959\n",
      "Epoch 10/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0961 - val_loss: 0.0945\n",
      "Epoch 11/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0947 - val_loss: 0.0926\n",
      "Epoch 12/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0942 - val_loss: 0.0935\n",
      "Epoch 13/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0931 - val_loss: 0.0918\n",
      "Epoch 14/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0925 - val_loss: 0.0909\n",
      "Epoch 15/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0914 - val_loss: 0.0889\n",
      "Epoch 16/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0906 - val_loss: 0.0880\n",
      "Epoch 17/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0897 - val_loss: 0.0879\n",
      "Epoch 18/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0894 - val_loss: 0.0872\n",
      "Epoch 19/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0883 - val_loss: 0.0872\n",
      "Epoch 20/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0870 - val_loss: 0.0854\n",
      "Epoch 21/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0865 - val_loss: 0.0859\n",
      "Epoch 22/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0867 - val_loss: 0.0860\n",
      "Epoch 23/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0861 - val_loss: 0.0847\n",
      "Epoch 24/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0857 - val_loss: 0.0836\n",
      "Epoch 25/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0840 - val_loss: 0.0828\n",
      "Epoch 26/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0842 - val_loss: 0.0858\n",
      "Epoch 27/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0837 - val_loss: 0.0831\n",
      "Epoch 28/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0822 - val_loss: 0.0818\n",
      "Epoch 29/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0823 - val_loss: 0.0859\n",
      "Epoch 30/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0826 - val_loss: 0.0807\n",
      "Epoch 31/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0815 - val_loss: 0.0803\n",
      "Epoch 32/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0808 - val_loss: 0.0803\n",
      "Epoch 33/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0817 - val_loss: 0.0820\n",
      "Epoch 34/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0810 - val_loss: 0.0788\n",
      "Epoch 35/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0799 - val_loss: 0.0795\n",
      "Epoch 36/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0801 - val_loss: 0.0781\n",
      "Epoch 37/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0788 - val_loss: 0.0811\n",
      "Epoch 38/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0781 - val_loss: 0.0775\n",
      "Epoch 39/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0783 - val_loss: 0.0795\n",
      "Epoch 40/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0784 - val_loss: 0.0780\n",
      "Epoch 41/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0780 - val_loss: 0.0793\n",
      "Epoch 42/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0772 - val_loss: 0.0775\n",
      "Epoch 43/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0770 - val_loss: 0.0786\n",
      "Epoch 44/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0761 - val_loss: 0.0781\n",
      "Epoch 45/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0764 - val_loss: 0.0769\n",
      "Epoch 46/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0760 - val_loss: 0.0754\n",
      "Epoch 47/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0753 - val_loss: 0.0784\n",
      "Epoch 48/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0741 - val_loss: 0.0749\n",
      "Epoch 49/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0735 - val_loss: 0.0760\n",
      "Epoch 50/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0739 - val_loss: 0.0724\n",
      "Epoch 51/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0733 - val_loss: 0.0749\n",
      "Epoch 52/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0730 - val_loss: 0.0733\n",
      "Epoch 53/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0733 - val_loss: 0.0738\n",
      "Epoch 54/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0726 - val_loss: 0.0754\n",
      "Epoch 55/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0720 - val_loss: 0.0717\n",
      "Epoch 56/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0724 - val_loss: 0.0799\n",
      "Epoch 57/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0721 - val_loss: 0.0722\n",
      "Epoch 58/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0710 - val_loss: 0.0726\n",
      "Epoch 59/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0707 - val_loss: 0.0740\n",
      "Epoch 60/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0704 - val_loss: 0.0712\n",
      "Epoch 61/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0707 - val_loss: 0.0730\n",
      "Epoch 62/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0697 - val_loss: 0.0709\n",
      "Epoch 63/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0693 - val_loss: 0.0699\n",
      "Epoch 64/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0687 - val_loss: 0.0698\n",
      "Epoch 65/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0691 - val_loss: 0.0699\n",
      "Epoch 66/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0685 - val_loss: 0.0704\n",
      "Epoch 67/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0688 - val_loss: 0.0690\n",
      "Epoch 68/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0681 - val_loss: 0.0698\n",
      "Epoch 69/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0681 - val_loss: 0.0710\n",
      "Epoch 70/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0676 - val_loss: 0.0696\n",
      "Epoch 71/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0668 - val_loss: 0.0693\n",
      "Epoch 72/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0667 - val_loss: 0.0673\n",
      "Epoch 73/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0658 - val_loss: 0.0713\n",
      "Epoch 74/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0656 - val_loss: 0.0669\n",
      "Epoch 75/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0664 - val_loss: 0.0694\n",
      "Epoch 76/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0655 - val_loss: 0.0667\n",
      "Epoch 77/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0644 - val_loss: 0.0684\n",
      "Epoch 78/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0650 - val_loss: 0.0676\n",
      "Epoch 79/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0639 - val_loss: 0.0656\n",
      "Epoch 80/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0641 - val_loss: 0.0660\n",
      "Epoch 81/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0637 - val_loss: 0.0646\n",
      "Epoch 82/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0632 - val_loss: 0.0650\n",
      "Epoch 83/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0626 - val_loss: 0.0642\n",
      "Epoch 84/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0629 - val_loss: 0.0669\n",
      "Epoch 85/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0625 - val_loss: 0.0638\n",
      "Epoch 86/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0618 - val_loss: 0.0676\n",
      "Epoch 87/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0613 - val_loss: 0.0647\n",
      "Epoch 88/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0617 - val_loss: 0.0629\n",
      "Epoch 89/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0612 - val_loss: 0.0638\n",
      "Epoch 90/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0610 - val_loss: 0.0640\n",
      "Epoch 91/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0609 - val_loss: 0.0643\n",
      "Epoch 92/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0602 - val_loss: 0.0644\n",
      "Epoch 93/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0606 - val_loss: 0.0646\n",
      "Epoch 94/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0597 - val_loss: 0.0644\n",
      "Epoch 95/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0601 - val_loss: 0.0618\n",
      "Epoch 96/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0587 - val_loss: 0.0593\n",
      "Epoch 97/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0590 - val_loss: 0.0605\n",
      "Epoch 98/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0596 - val_loss: 0.0612\n",
      "Epoch 99/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0587 - val_loss: 0.0586\n",
      "Epoch 100/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0585 - val_loss: 0.0626\n",
      "Epoch 101/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0586 - val_loss: 0.0599\n",
      "Epoch 102/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0579 - val_loss: 0.0590\n",
      "Epoch 103/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0588 - val_loss: 0.0620\n",
      "Epoch 104/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0574 - val_loss: 0.0594\n",
      "Epoch 105/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0584 - val_loss: 0.0597\n",
      "Epoch 106/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0563 - val_loss: 0.0577\n",
      "Epoch 107/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0584 - val_loss: 0.0613\n",
      "Epoch 108/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0567 - val_loss: 0.0599\n",
      "Epoch 109/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0567 - val_loss: 0.0599\n",
      "Epoch 110/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0563 - val_loss: 0.0599\n",
      "Epoch 111/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0556 - val_loss: 0.0582\n",
      "Epoch 112/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0557 - val_loss: 0.0580\n",
      "Epoch 113/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0559 - val_loss: 0.0636\n",
      "Epoch 114/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0565 - val_loss: 0.0607\n",
      "Epoch 115/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0554 - val_loss: 0.0578\n",
      "Epoch 116/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0542 - val_loss: 0.0567\n",
      "Epoch 117/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0555 - val_loss: 0.0591\n",
      "Epoch 118/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0546 - val_loss: 0.0577\n",
      "Epoch 119/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0554 - val_loss: 0.0559\n",
      "Epoch 120/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0538 - val_loss: 0.0582\n",
      "Epoch 121/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0542 - val_loss: 0.0567\n",
      "Epoch 122/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0544 - val_loss: 0.0566\n",
      "Epoch 123/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0532 - val_loss: 0.0572\n",
      "Epoch 124/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0533 - val_loss: 0.0583\n",
      "Epoch 125/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0544 - val_loss: 0.0577\n",
      "Epoch 126/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0543 - val_loss: 0.0565\n",
      "Epoch 127/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0530 - val_loss: 0.0546\n",
      "Epoch 128/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0524 - val_loss: 0.0545\n",
      "Epoch 129/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0524 - val_loss: 0.0548\n",
      "Epoch 130/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0522 - val_loss: 0.0555\n",
      "Epoch 131/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0526 - val_loss: 0.0540\n",
      "Epoch 132/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0524 - val_loss: 0.0597\n",
      "Epoch 133/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0512 - val_loss: 0.0555\n",
      "Epoch 134/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0521 - val_loss: 0.0572\n",
      "Epoch 135/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0522 - val_loss: 0.0580\n",
      "Epoch 136/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0530 - val_loss: 0.0562\n",
      "Epoch 137/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0510 - val_loss: 0.0538\n",
      "Epoch 138/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0516 - val_loss: 0.0546\n",
      "Epoch 139/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0514 - val_loss: 0.0563\n",
      "Epoch 140/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0504 - val_loss: 0.0527\n",
      "Epoch 141/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0501 - val_loss: 0.0544\n",
      "Epoch 142/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0509 - val_loss: 0.0562\n",
      "Epoch 143/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0513 - val_loss: 0.0548\n",
      "Epoch 144/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0507 - val_loss: 0.0541\n",
      "Epoch 145/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0497 - val_loss: 0.0562\n",
      "Epoch 146/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0498 - val_loss: 0.0539\n",
      "Epoch 147/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0503 - val_loss: 0.0520\n",
      "Epoch 148/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0510 - val_loss: 0.0533\n",
      "Epoch 149/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0495 - val_loss: 0.0544\n",
      "Epoch 150/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0503 - val_loss: 0.0530\n",
      "Epoch 151/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0492 - val_loss: 0.0569\n",
      "Epoch 152/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0488 - val_loss: 0.0533\n",
      "Epoch 153/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0490 - val_loss: 0.0544\n",
      "Epoch 154/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0487 - val_loss: 0.0515\n",
      "Epoch 155/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0484 - val_loss: 0.0549\n",
      "Epoch 156/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0495 - val_loss: 0.0579\n",
      "Epoch 157/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0478 - val_loss: 0.0508\n",
      "Epoch 158/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0490 - val_loss: 0.0525\n",
      "Epoch 159/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0483 - val_loss: 0.0556\n",
      "Epoch 160/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0487 - val_loss: 0.0509\n",
      "Epoch 161/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0490 - val_loss: 0.0563\n",
      "Epoch 162/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0483 - val_loss: 0.0508\n",
      "Epoch 163/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0472 - val_loss: 0.0511\n",
      "Epoch 164/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0484 - val_loss: 0.0513\n",
      "Epoch 165/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0466 - val_loss: 0.0551\n",
      "Epoch 166/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0475 - val_loss: 0.0492\n",
      "Epoch 167/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0469 - val_loss: 0.0514\n",
      "Epoch 168/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0468 - val_loss: 0.0496\n",
      "Epoch 169/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0465 - val_loss: 0.0509\n",
      "Epoch 170/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0472 - val_loss: 0.0564\n",
      "Epoch 171/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0479 - val_loss: 0.0533\n",
      "Epoch 172/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0466 - val_loss: 0.0507\n",
      "Epoch 173/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0453 - val_loss: 0.0507\n",
      "Epoch 174/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0457 - val_loss: 0.0495\n",
      "Epoch 175/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0458 - val_loss: 0.0565\n",
      "Epoch 176/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0465 - val_loss: 0.0524\n",
      "Epoch 177/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0456 - val_loss: 0.0490\n",
      "Epoch 178/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0456 - val_loss: 0.0500\n",
      "Epoch 179/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0467 - val_loss: 0.0508\n",
      "Epoch 180/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0463 - val_loss: 0.0506\n",
      "Epoch 181/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0457 - val_loss: 0.0507\n",
      "Epoch 182/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0455 - val_loss: 0.0505\n",
      "Epoch 183/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0451 - val_loss: 0.0479\n",
      "Epoch 184/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0470 - val_loss: 0.0536\n",
      "Epoch 185/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0459 - val_loss: 0.0506\n",
      "Epoch 186/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0449 - val_loss: 0.0479\n",
      "Epoch 187/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0447 - val_loss: 0.0482\n",
      "Epoch 188/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0447 - val_loss: 0.0493\n",
      "Epoch 189/300\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0444 - val_loss: 0.0485\n",
      "Epoch 190/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0450 - val_loss: 0.0496\n",
      "Epoch 191/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0451 - val_loss: 0.0471\n",
      "Epoch 192/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0438 - val_loss: 0.0502\n",
      "Epoch 193/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0445 - val_loss: 0.0464\n",
      "Epoch 194/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0445 - val_loss: 0.0503\n",
      "Epoch 195/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0445 - val_loss: 0.0474\n",
      "Epoch 196/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0449 - val_loss: 0.0497\n",
      "Epoch 197/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0442 - val_loss: 0.0469\n",
      "Epoch 198/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0446 - val_loss: 0.0476\n",
      "Epoch 199/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0434 - val_loss: 0.0466\n",
      "Epoch 200/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0432 - val_loss: 0.0465\n",
      "Epoch 201/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0427 - val_loss: 0.0474\n",
      "Epoch 202/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0436 - val_loss: 0.0489\n",
      "Epoch 203/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0435 - val_loss: 0.0499\n",
      "Epoch 204/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0445 - val_loss: 0.0485\n",
      "Epoch 205/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0431 - val_loss: 0.0452\n",
      "Epoch 206/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0426 - val_loss: 0.0480\n",
      "Epoch 207/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0431 - val_loss: 0.0476\n",
      "Epoch 208/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0435 - val_loss: 0.0452\n",
      "Epoch 209/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0437 - val_loss: 0.0467\n",
      "Epoch 210/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0427 - val_loss: 0.0458\n",
      "Epoch 211/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0427 - val_loss: 0.0473\n",
      "Epoch 212/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0427 - val_loss: 0.0495\n",
      "Epoch 213/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0427 - val_loss: 0.0454\n",
      "Epoch 214/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0415 - val_loss: 0.0467\n",
      "Epoch 215/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0429 - val_loss: 0.0469\n",
      "Epoch 216/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0418 - val_loss: 0.0450\n",
      "Epoch 217/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0416 - val_loss: 0.0457\n",
      "Epoch 218/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0432 - val_loss: 0.0460\n",
      "Epoch 219/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0429 - val_loss: 0.0493\n",
      "Epoch 220/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0424 - val_loss: 0.0455\n",
      "Epoch 221/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0423 - val_loss: 0.0472\n",
      "Epoch 222/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0410 - val_loss: 0.0458\n",
      "Epoch 223/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0420 - val_loss: 0.0455\n",
      "Epoch 224/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0422 - val_loss: 0.0449\n",
      "Epoch 225/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0406 - val_loss: 0.0475\n",
      "Epoch 226/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0421 - val_loss: 0.0495\n",
      "Epoch 227/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0417 - val_loss: 0.0436\n",
      "Epoch 228/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0405 - val_loss: 0.0441\n",
      "Epoch 229/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0416 - val_loss: 0.0458\n",
      "Epoch 230/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0412 - val_loss: 0.0439\n",
      "Epoch 231/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0410 - val_loss: 0.0459\n",
      "Epoch 232/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0416 - val_loss: 0.0438\n",
      "Epoch 233/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0416 - val_loss: 0.0506\n",
      "Epoch 234/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0416 - val_loss: 0.0461\n",
      "Epoch 235/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0414 - val_loss: 0.0438\n",
      "Epoch 236/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0408 - val_loss: 0.0438\n",
      "Epoch 237/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0393 - val_loss: 0.0447\n",
      "Epoch 238/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0406 - val_loss: 0.0441\n",
      "Epoch 239/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0413 - val_loss: 0.0450\n",
      "Epoch 240/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0401 - val_loss: 0.0463\n",
      "Epoch 241/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0406 - val_loss: 0.0435\n",
      "Epoch 242/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0395 - val_loss: 0.0443\n",
      "Epoch 243/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0409 - val_loss: 0.0433\n",
      "Epoch 244/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0395 - val_loss: 0.0449\n",
      "Epoch 245/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0405 - val_loss: 0.0459\n",
      "Epoch 246/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0398 - val_loss: 0.0446\n",
      "Epoch 247/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0416 - val_loss: 0.0427\n",
      "Epoch 248/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0389 - val_loss: 0.0417\n",
      "Epoch 249/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0393 - val_loss: 0.0429\n",
      "Epoch 250/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0398 - val_loss: 0.0427\n",
      "Epoch 251/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0398 - val_loss: 0.0488\n",
      "Epoch 252/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0405 - val_loss: 0.0420\n",
      "Epoch 253/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0402 - val_loss: 0.0450\n",
      "Epoch 254/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0408 - val_loss: 0.0471\n",
      "Epoch 255/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0391 - val_loss: 0.0439\n",
      "Epoch 256/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0394 - val_loss: 0.0445\n",
      "Epoch 257/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0392 - val_loss: 0.0431\n",
      "Epoch 258/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0392 - val_loss: 0.0432\n",
      "Epoch 259/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0388 - val_loss: 0.0437\n",
      "Epoch 260/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0398 - val_loss: 0.0410\n",
      "Epoch 261/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0387 - val_loss: 0.0434\n",
      "Epoch 262/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0385 - val_loss: 0.0462\n",
      "Epoch 263/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0403 - val_loss: 0.0435\n",
      "Epoch 264/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0387 - val_loss: 0.0424\n",
      "Epoch 265/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0391 - val_loss: 0.0444\n",
      "Epoch 266/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0380 - val_loss: 0.0438\n",
      "Epoch 267/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0394 - val_loss: 0.0442\n",
      "Epoch 268/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0382 - val_loss: 0.0463\n",
      "Epoch 269/300\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0395 - val_loss: 0.0427\n",
      "Epoch 270/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0391 - val_loss: 0.0428\n",
      "Epoch 271/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0376 - val_loss: 0.0464\n",
      "Epoch 272/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0381 - val_loss: 0.0414\n",
      "Epoch 273/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0385 - val_loss: 0.0421\n",
      "Epoch 274/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0389 - val_loss: 0.0419\n",
      "Epoch 275/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0385 - val_loss: 0.0406\n",
      "Epoch 276/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0379 - val_loss: 0.0432\n",
      "Epoch 277/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0381 - val_loss: 0.0445\n",
      "Epoch 278/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0372 - val_loss: 0.0427\n",
      "Epoch 279/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0378 - val_loss: 0.0410\n",
      "Epoch 280/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0379 - val_loss: 0.0424\n",
      "Epoch 281/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0387 - val_loss: 0.0426\n",
      "Epoch 282/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0381 - val_loss: 0.0434\n",
      "Epoch 283/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0381 - val_loss: 0.0450\n",
      "Epoch 284/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0377 - val_loss: 0.0402\n",
      "Epoch 285/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0375 - val_loss: 0.0447\n",
      "Epoch 286/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0383 - val_loss: 0.0437\n",
      "Epoch 287/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0380 - val_loss: 0.0419\n",
      "Epoch 288/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0367 - val_loss: 0.0385\n",
      "Epoch 289/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0370 - val_loss: 0.0426\n",
      "Epoch 290/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0373 - val_loss: 0.0417\n",
      "Epoch 291/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0379 - val_loss: 0.0437\n",
      "Epoch 292/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0376 - val_loss: 0.0413\n",
      "Epoch 293/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0381 - val_loss: 0.0417\n",
      "Epoch 294/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0371 - val_loss: 0.0401\n",
      "Epoch 295/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0384 - val_loss: 0.0482\n",
      "Epoch 296/300\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0372 - val_loss: 0.0404\n",
      "Epoch 297/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0374 - val_loss: 0.0404\n",
      "Epoch 298/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0365 - val_loss: 0.0423\n",
      "Epoch 299/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0363 - val_loss: 0.0400\n",
      "Epoch 300/300\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0372 - val_loss: 0.0415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f34c1ebd2e0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.compile(trainer, loss)\n",
    "net.fit(\n",
    "    x = X_train,\n",
    "    y = y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs,\n",
    "    validation_split=0.1,\n",
    "    use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "10850a00-5a2b-4ebc-8e01-a697d3b1a7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 [==============================] - 8s 1ms/step - loss: 0.0750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07501960545778275"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.evaluate(x=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "07151698-d52c-4716-8522-3c516a6e78dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save('model-temp.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9731516d-0da9-4f5a-ba39-5da5b2a67b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('model-temp.hdf5')\n",
    "def nnController(initialState, finalState):\n",
    "    relativeInitial, relativeFinal = utils.absoluteToRelative(initialState, finalState)\n",
    "    inputVector = tf.constant([\n",
    "        relativeInitial[0],\n",
    "        relativeFinal[0],\n",
    "        relativeFinal[1],\n",
    "        relativeFinal[2],\n",
    "        relativeFinal[3]\n",
    "    ], shape=(1,5))\n",
    "    #normalizedInput = scaler.transform(inputVector)\n",
    "    predictedControl = loaded_model.predict(inputVector)\n",
    "    return np.array([predictedControl[0][0], predictedControl[0][1]], dtype=np.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c6b9771b-a818-45d8-8c5e-168b79d04f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "initialState = np.array([0, 0, 0, 0], dtype=np.double)\n",
    "targetState = np.array([100, 0, 0, np.pi/4], dtype=np.double)\n",
    "\n",
    "sim = simulation.Simulation(\n",
    "    initialState,\n",
    "    targetState,\n",
    "    10.0,\n",
    "    nnController,\n",
    "    stopRadius=5.0)\n",
    "\n",
    "sim.runSimulation(30.0, quiet=True)\n",
    "simulation.plot_path(sim, fileName=\"model-example.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5546b201-1581-4fa2-84f1-a7d588b860da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
